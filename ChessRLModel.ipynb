{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8bd30ca-6841-41bc-afe4-6c3951e7e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import chess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# %run ChessBoardEnv.ipynb\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf7a211-d9c9-4971-905d-bb8bdcdf633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mapped():\n",
    "    mapped = {\n",
    "            'P': 1,     # White Pawn\n",
    "            'p': -1,    # Black Pawn\n",
    "            'N': 2,     # White Knight\n",
    "            'n': -2,    # Black Knight\n",
    "            'B': 3,     # White Bishop\n",
    "            'b': -3,    # Black Bishop\n",
    "            'R': 4,     # White Rook\n",
    "            'r': -4,    # Black Rook\n",
    "            'Q': 5,     # White Queen\n",
    "            'q': -5,    # Black Queen\n",
    "            'K': 6,     # White King\n",
    "            'k': -6     # Black King\n",
    "            }\n",
    "    return mapped\n",
    "def get_positions()->np.array:\n",
    "    letters = ['a','b','c','d','e','f','g','h']\n",
    "    numbers = [str(num) for num in range(1,9) ]\n",
    "    promote_piece_letters = ['r','q','b','n']\n",
    "    positions = []\n",
    "    # second_positions = []\n",
    "    #all squares\n",
    "    for letter in letters:\n",
    "        for number in numbers:\n",
    "            positions.append(f'{letter}{number}')\n",
    "            # second_positions.append(f'{letter}{number}')\n",
    "    #squares with promotion\n",
    "    promotion_numbers = [1,8]\n",
    "    for letter in letters:\n",
    "        for number in promotion_numbers:\n",
    "            for piece_letter in promote_piece_letters:\n",
    "                positions.append(f'{letter}{number}{piece_letter}')\n",
    "    \n",
    "    positions = np.array(positions,dtype=object)\n",
    "    return positions\n",
    "\n",
    "class ChessBoardEnv():\n",
    "    def __init__(self):\n",
    "        self.black_mapped = {\n",
    "         #black pieces\n",
    "        'p': 1,    \n",
    "        'n': 3,    \n",
    "        'b': 3,    \n",
    "        'r': 5,    \n",
    "        'q': 9\n",
    "        }\n",
    "        self.white_mapped = {\n",
    "            'P':1,\n",
    "            'N':3,\n",
    "            'B':3,\n",
    "            'R':5,\n",
    "            'Q':9\n",
    "        }\n",
    "        self.board = chess.Board()\n",
    "        self.n_observations = 64\n",
    "        self.action_space = get_positions()\n",
    "    \n",
    "    def get_legal_moves(self)->np.array:\n",
    "        legal_moves = [str(move) for move in list(self.board.legal_moves)]\n",
    "        legal_moves = np.array(legal_moves,dtype='object')\n",
    "        return legal_moves\n",
    "        \n",
    "    def sample(self)->list:\n",
    "        moves_list = self.get_legal_moves()\n",
    "        choice = np.random.choice(moves_list)\n",
    "        print(choice)\n",
    "        from_position = np.where(self.action_space == choice[:2])[0][0]\n",
    "        to_position = np.where(self.action_space == choice[2:])[0][0]\n",
    "        return [from_position,to_position]\n",
    "        \n",
    "    # def to_uci(self)\n",
    "    def state(self)->np.array: #this function defines State\n",
    "        pgn = self.board.epd()\n",
    "        array = []  #Final board\n",
    "        pieces = pgn.split(\" \", 1)[0]\n",
    "        rows = pieces.split(\"/\")\n",
    "        mapped = get_mapped()\n",
    "        for row in rows:\n",
    "            array2 = []  #Row\n",
    "            for thing in row:\n",
    "                if thing.isdigit():\n",
    "                    for i in range(0, int(thing)):\n",
    "                        array2.append(0)\n",
    "                else:\n",
    "                    array2.append(mapped[thing])\n",
    "            array.append(array2)\n",
    "        return np.array(array,dtype=np.int16).reshape(1,64)\n",
    "\n",
    "    \n",
    "    def next_state(self,move_str):\n",
    "        move = chess.Move.from_uci(move_str)\n",
    "        if move in self.board.legal_moves:\n",
    "            self.board.push(move)\n",
    "        else:\n",
    "            print(\"not legal move\")\n",
    "        next_state = self.board.epd()\n",
    "        self.board.pop()\n",
    "        return next_state\n",
    "\n",
    "    def make_move(self,move_str)-> None:\n",
    "        move = chess.Move.from_uci(move_str)\n",
    "        if move in self.board.legal_moves:\n",
    "            self.board.push(move)\n",
    "        else:\n",
    "            raise Exception(\"Illegal move\")\n",
    "        \n",
    "    \n",
    "    def calculate_reward_for_move(self):\n",
    "        color = 'black' if self.board.turn else 'white' # if turn is True(white) then last move was made by black and vice versa\n",
    "        \n",
    "        if self.board.is_checkmate():\n",
    "            if color == 'white':\n",
    "                return torch.tensor(1.0,device=device, dtype=torch.float32)\n",
    "            elif color == 'black':\n",
    "                return torch.tensor(-1.0, device=device, dtype=torch.float32)\n",
    "        else:\n",
    "            return torch.tensor(-0.001, device=device, dtype=torch.float32)\n",
    "        \n",
    "        if self.board.is_fifty_moves() or self.board.is_stalemate():\n",
    "            return torch.tensor(-1.0, device=device, dtype=torch.float32)\n",
    "            \n",
    "    def reset(self):\n",
    "        self.board.reset()\n",
    "        return self.board.fen\n",
    "        \n",
    "    def step(self, move_list):\n",
    "        move_str = f\"{self.action_space[move_list[0].item()]}{self.action_space[move_list[1].item()]}\"\n",
    "        self.make_move(move_str)\n",
    "        reward = self.calculate_reward_for_move()\n",
    "        turn = 'white' if self.board.turn else 'black'\n",
    "        observation = self.state()\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        if self.board.is_checkmate() or self.board.is_stalemate():\n",
    "            terminated = True\n",
    "        if self.board.is_fifty_moves():\n",
    "            truncated = True\n",
    "        return observation,reward,terminated,truncated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env = ChessBoardEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5a43d2-d094-4a89-b532-74dc0f14e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596976d6-93bd-47b7-95af-d891a5cee9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDimLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_shape, **kwargs):\n",
    "        self.out_shape = out_shape\n",
    "        out_features = np.prod(out_shape)\n",
    "        super().__init__(in_features, out_features, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = super().forward(x)\n",
    "        return out.reshape((len(x), *self.out_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14cd2eb0-3992-4deb-8a5d-c33b15c9cd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e490579-8110-46d5-8c58-b3ec7607b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = MultiDimLinear(in_features=128, out_shape=(2, len(env.action_space)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        output = F.softmax(self.layer3(x),dim=2)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e9036-3d7d-4013-8e1c-76accf08b452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f8c1fc-6c4b-4f47-9547-83ac2fe3e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be1b0b7-366a-4f17-8904-64c16191b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "n_observations = env.n_observations\n",
    "print(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a451874-e0b2-4264-9384-efce67898131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "policy_net = DQN(n_observations).to(device)\n",
    "target_net = DQN(n_observations).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7f38ab-63ad-474e-83d9-3baaf9124f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\warfa\\.conda\\envs\\AI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2feb970-0096-4b34-afad-cae111b91ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = np.random.rand(64)\n",
    "# state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "# # policy_net(state).max(dim=2).indices.view(2)\n",
    "# print(env.sample())\n",
    "# # torch.tensor(env.sample(), device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d205bba-c139-402e-876e-b9a9c2da3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state,board:chess.Board)->list:\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                    math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    move = None\n",
    "    while move not in board.legal_moves:\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return the largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action_tensor =  policy_net(state).max(dim=2).indices.view(2)\n",
    "                sample = random.random()\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            print(\"else\")\n",
    "            return torch.tensor([env.sample()], device=device, dtype=torch.long).view(1,2,1)\n",
    "        \n",
    "        from_position = env.action_space[action_tensor[0]-1]\n",
    "        to_position = env.action_space[action_tensor[1]-1]\n",
    "        uci = f'{from_position}{to_position}'\n",
    "        if from_position != to_position:\n",
    "            try:\n",
    "                move = chess.Move.from_uci(uci)\n",
    "            except:\n",
    "                move = None\n",
    "        else:\n",
    "            move = None\n",
    "    return torch.tensor([[[from_position],[to_position]]], device=device, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42624947-7f15-463b-8ed0-1d21e326fd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1h3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[48],\n",
       "         [58]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([env.sample()], device=device, dtype=torch.long).view(1,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a3b6bc-c13e-4126-ad01-8888ff00892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "state = env.state() \n",
    "state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "print(state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19901845-8a84-4aee-9eb9-7509ef24c2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n",
      "d2d3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([25], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action = select_action(state,env.board)\n",
    "action[0][0]\n",
    "# observation, reward, terminated, truncated = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "971b0487-821a-4c45-90d5-3ef504db9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "        \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(2, action_batch)\n",
    "    \n",
    "    next_state_values = torch.zeros((BATCH_SIZE,2), device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(2).values\n",
    "    print(next_state_values)\n",
    "    print(next_state_values * GAMMA)\n",
    "    print(reward_batch)\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + torch.tensor([reward_batch,reward_batch],device=device,dtype=torch.long)\n",
    "\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbfd98b1-262a-48c5-9837-d035ac24fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n",
      "d6d7\n",
      "action: tensor([[[29],\n",
      "         [30]]], device='cuda:0')\n",
      "tensor(-0.0010, device='cuda:0')\n",
      "tensor([[0.0124, 0.0141],\n",
      "        [0.0124, 0.0112],\n",
      "        [0.0112, 0.0113],\n",
      "        [0.0124, 0.0136],\n",
      "        [0.0138, 0.0130],\n",
      "        [0.0109, 0.0110],\n",
      "        [0.0114, 0.0124],\n",
      "        [0.0121, 0.0140],\n",
      "        [0.0129, 0.0133],\n",
      "        [0.0116, 0.0113],\n",
      "        [0.0103, 0.0113],\n",
      "        [0.0113, 0.0110],\n",
      "        [0.0129, 0.0123],\n",
      "        [0.0125, 0.0115],\n",
      "        [0.0105, 0.0113],\n",
      "        [0.0103, 0.0121],\n",
      "        [0.0119, 0.0120],\n",
      "        [0.0124, 0.0136],\n",
      "        [0.0122, 0.0120],\n",
      "        [0.0122, 0.0124],\n",
      "        [0.0134, 0.0128],\n",
      "        [0.0128, 0.0126],\n",
      "        [0.0140, 0.0130],\n",
      "        [0.0124, 0.0109],\n",
      "        [0.0104, 0.0109],\n",
      "        [0.0128, 0.0115],\n",
      "        [0.0135, 0.0134],\n",
      "        [0.0119, 0.0123],\n",
      "        [0.0127, 0.0118],\n",
      "        [0.0123, 0.0110],\n",
      "        [0.0119, 0.0111],\n",
      "        [0.0118, 0.0134],\n",
      "        [0.0127, 0.0124],\n",
      "        [0.0121, 0.0112],\n",
      "        [0.0106, 0.0112],\n",
      "        [0.0112, 0.0113],\n",
      "        [0.0119, 0.0119],\n",
      "        [0.0124, 0.0137],\n",
      "        [0.0124, 0.0117],\n",
      "        [0.0124, 0.0136],\n",
      "        [0.0125, 0.0137],\n",
      "        [0.0119, 0.0111],\n",
      "        [0.0126, 0.0122],\n",
      "        [0.0106, 0.0111],\n",
      "        [0.0120, 0.0123],\n",
      "        [0.0108, 0.0111],\n",
      "        [0.0122, 0.0124],\n",
      "        [0.0121, 0.0126],\n",
      "        [0.0118, 0.0112],\n",
      "        [0.0122, 0.0135],\n",
      "        [0.0111, 0.0117],\n",
      "        [0.0126, 0.0135],\n",
      "        [0.0119, 0.0115],\n",
      "        [0.0125, 0.0128],\n",
      "        [0.0113, 0.0119],\n",
      "        [0.0124, 0.0121],\n",
      "        [0.0125, 0.0135],\n",
      "        [0.0111, 0.0115],\n",
      "        [0.0124, 0.0114],\n",
      "        [0.0125, 0.0137],\n",
      "        [0.0114, 0.0116],\n",
      "        [0.0140, 0.0123],\n",
      "        [0.0109, 0.0127],\n",
      "        [0.0125, 0.0123],\n",
      "        [0.0121, 0.0119],\n",
      "        [0.0121, 0.0120],\n",
      "        [0.0124, 0.0119],\n",
      "        [0.0117, 0.0134],\n",
      "        [0.0122, 0.0135],\n",
      "        [0.0105, 0.0108],\n",
      "        [0.0123, 0.0120],\n",
      "        [0.0112, 0.0109],\n",
      "        [0.0132, 0.0132],\n",
      "        [0.0114, 0.0119],\n",
      "        [0.0122, 0.0116],\n",
      "        [0.0118, 0.0131],\n",
      "        [0.0116, 0.0113],\n",
      "        [0.0135, 0.0128],\n",
      "        [0.0125, 0.0118],\n",
      "        [0.0132, 0.0122],\n",
      "        [0.0120, 0.0117],\n",
      "        [0.0134, 0.0134],\n",
      "        [0.0124, 0.0126],\n",
      "        [0.0104, 0.0107],\n",
      "        [0.0102, 0.0107],\n",
      "        [0.0126, 0.0123],\n",
      "        [0.0102, 0.0108],\n",
      "        [0.0125, 0.0123],\n",
      "        [0.0131, 0.0127],\n",
      "        [0.0130, 0.0138],\n",
      "        [0.0123, 0.0144],\n",
      "        [0.0127, 0.0137],\n",
      "        [0.0122, 0.0124],\n",
      "        [0.0128, 0.0137],\n",
      "        [0.0125, 0.0135],\n",
      "        [0.0129, 0.0122],\n",
      "        [0.0106, 0.0113],\n",
      "        [0.0120, 0.0123],\n",
      "        [0.0108, 0.0108],\n",
      "        [0.0121, 0.0129],\n",
      "        [0.0115, 0.0125],\n",
      "        [0.0125, 0.0139],\n",
      "        [0.0109, 0.0109],\n",
      "        [0.0123, 0.0130],\n",
      "        [0.0102, 0.0121],\n",
      "        [0.0124, 0.0138],\n",
      "        [0.0111, 0.0113],\n",
      "        [0.0120, 0.0116],\n",
      "        [0.0110, 0.0111],\n",
      "        [0.0125, 0.0134],\n",
      "        [0.0098, 0.0107],\n",
      "        [0.0106, 0.0108],\n",
      "        [0.0120, 0.0134],\n",
      "        [0.0129, 0.0133],\n",
      "        [0.0125, 0.0117],\n",
      "        [0.0111, 0.0132],\n",
      "        [0.0124, 0.0121],\n",
      "        [0.0122, 0.0124],\n",
      "        [0.0131, 0.0124],\n",
      "        [0.0107, 0.0107],\n",
      "        [0.0100, 0.0108],\n",
      "        [0.0131, 0.0126],\n",
      "        [0.0119, 0.0133],\n",
      "        [0.0114, 0.0114],\n",
      "        [0.0125, 0.0116],\n",
      "        [0.0123, 0.0139],\n",
      "        [0.0102, 0.0110],\n",
      "        [0.0126, 0.0119]], device='cuda:0')\n",
      "tensor([[0.0123, 0.0139],\n",
      "        [0.0122, 0.0111],\n",
      "        [0.0110, 0.0112],\n",
      "        [0.0123, 0.0134],\n",
      "        [0.0137, 0.0128],\n",
      "        [0.0108, 0.0109],\n",
      "        [0.0113, 0.0123],\n",
      "        [0.0120, 0.0138],\n",
      "        [0.0128, 0.0131],\n",
      "        [0.0115, 0.0112],\n",
      "        [0.0102, 0.0112],\n",
      "        [0.0112, 0.0109],\n",
      "        [0.0127, 0.0121],\n",
      "        [0.0124, 0.0114],\n",
      "        [0.0104, 0.0112],\n",
      "        [0.0102, 0.0120],\n",
      "        [0.0118, 0.0119],\n",
      "        [0.0123, 0.0135],\n",
      "        [0.0121, 0.0119],\n",
      "        [0.0121, 0.0122],\n",
      "        [0.0132, 0.0126],\n",
      "        [0.0127, 0.0125],\n",
      "        [0.0139, 0.0129],\n",
      "        [0.0123, 0.0108],\n",
      "        [0.0102, 0.0108],\n",
      "        [0.0126, 0.0113],\n",
      "        [0.0134, 0.0133],\n",
      "        [0.0118, 0.0122],\n",
      "        [0.0126, 0.0116],\n",
      "        [0.0122, 0.0109],\n",
      "        [0.0118, 0.0110],\n",
      "        [0.0116, 0.0133],\n",
      "        [0.0126, 0.0123],\n",
      "        [0.0120, 0.0111],\n",
      "        [0.0105, 0.0111],\n",
      "        [0.0111, 0.0112],\n",
      "        [0.0118, 0.0118],\n",
      "        [0.0123, 0.0136],\n",
      "        [0.0123, 0.0116],\n",
      "        [0.0123, 0.0135],\n",
      "        [0.0124, 0.0135],\n",
      "        [0.0118, 0.0110],\n",
      "        [0.0125, 0.0121],\n",
      "        [0.0105, 0.0110],\n",
      "        [0.0119, 0.0122],\n",
      "        [0.0107, 0.0110],\n",
      "        [0.0121, 0.0123],\n",
      "        [0.0120, 0.0125],\n",
      "        [0.0117, 0.0111],\n",
      "        [0.0121, 0.0133],\n",
      "        [0.0110, 0.0116],\n",
      "        [0.0125, 0.0134],\n",
      "        [0.0118, 0.0114],\n",
      "        [0.0123, 0.0126],\n",
      "        [0.0112, 0.0118],\n",
      "        [0.0123, 0.0120],\n",
      "        [0.0124, 0.0134],\n",
      "        [0.0109, 0.0114],\n",
      "        [0.0123, 0.0113],\n",
      "        [0.0124, 0.0136],\n",
      "        [0.0113, 0.0115],\n",
      "        [0.0138, 0.0122],\n",
      "        [0.0108, 0.0126],\n",
      "        [0.0124, 0.0122],\n",
      "        [0.0120, 0.0118],\n",
      "        [0.0120, 0.0119],\n",
      "        [0.0123, 0.0118],\n",
      "        [0.0116, 0.0132],\n",
      "        [0.0121, 0.0134],\n",
      "        [0.0104, 0.0107],\n",
      "        [0.0122, 0.0119],\n",
      "        [0.0111, 0.0108],\n",
      "        [0.0131, 0.0130],\n",
      "        [0.0112, 0.0118],\n",
      "        [0.0121, 0.0115],\n",
      "        [0.0116, 0.0130],\n",
      "        [0.0115, 0.0112],\n",
      "        [0.0134, 0.0127],\n",
      "        [0.0124, 0.0117],\n",
      "        [0.0130, 0.0121],\n",
      "        [0.0119, 0.0116],\n",
      "        [0.0133, 0.0132],\n",
      "        [0.0122, 0.0125],\n",
      "        [0.0103, 0.0106],\n",
      "        [0.0101, 0.0106],\n",
      "        [0.0125, 0.0122],\n",
      "        [0.0101, 0.0107],\n",
      "        [0.0124, 0.0122],\n",
      "        [0.0129, 0.0126],\n",
      "        [0.0128, 0.0137],\n",
      "        [0.0122, 0.0142],\n",
      "        [0.0126, 0.0136],\n",
      "        [0.0121, 0.0123],\n",
      "        [0.0127, 0.0135],\n",
      "        [0.0123, 0.0134],\n",
      "        [0.0127, 0.0121],\n",
      "        [0.0105, 0.0112],\n",
      "        [0.0119, 0.0122],\n",
      "        [0.0107, 0.0107],\n",
      "        [0.0120, 0.0128],\n",
      "        [0.0114, 0.0124],\n",
      "        [0.0123, 0.0138],\n",
      "        [0.0108, 0.0108],\n",
      "        [0.0122, 0.0128],\n",
      "        [0.0101, 0.0120],\n",
      "        [0.0122, 0.0137],\n",
      "        [0.0110, 0.0112],\n",
      "        [0.0118, 0.0115],\n",
      "        [0.0109, 0.0110],\n",
      "        [0.0124, 0.0133],\n",
      "        [0.0097, 0.0106],\n",
      "        [0.0105, 0.0107],\n",
      "        [0.0119, 0.0132],\n",
      "        [0.0128, 0.0132],\n",
      "        [0.0124, 0.0116],\n",
      "        [0.0110, 0.0131],\n",
      "        [0.0123, 0.0120],\n",
      "        [0.0121, 0.0123],\n",
      "        [0.0130, 0.0123],\n",
      "        [0.0105, 0.0106],\n",
      "        [0.0099, 0.0107],\n",
      "        [0.0129, 0.0124],\n",
      "        [0.0118, 0.0132],\n",
      "        [0.0113, 0.0113],\n",
      "        [0.0123, 0.0115],\n",
      "        [0.0122, 0.0137],\n",
      "        [0.0101, 0.0109],\n",
      "        [0.0124, 0.0117]], device='cuda:0')\n",
      "tensor([-0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010,\n",
      "        -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010, -0.0010],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Perform one step of the optimization (on the policy network)\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Soft update of the target network's weights\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# θ′ ← τ θ + (1 −τ )θ′\u001b[39;00m\n\u001b[0;32m     35\u001b[0m target_net_state_dict \u001b[38;5;241m=\u001b[39m target_net\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "Cell \u001b[1;32mIn[27], line 23\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(next_state_values \u001b[38;5;241m*\u001b[39m GAMMA)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(reward_batch)\n\u001b[1;32m---> 23\u001b[0m expected_state_action_values \u001b[38;5;241m=\u001b[39m (next_state_values \u001b[38;5;241m*\u001b[39m GAMMA) \u001b[38;5;241m+\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreward_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreward_batch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSmoothL1Loss()\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(state_action_values, expected_state_action_values\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state = env.state() \n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    for t in count():\n",
    "        action = select_action(state,env.board)\n",
    "        print(\"action:\",action)\n",
    "        observation, reward, terminated, truncated = env.step(action[0])\n",
    "        print(reward)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50b434ca-8f7a-46f9-8a02-d30f36878c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = (torch.tensor([[[2],[3]]], device=device), torch.tensor([[[3],[0]]], device=device))\n",
    "state_action_values = torch.tensor([[[0.0078, 0.0102, 0.0108, 0.0053],\n",
    "         [0.0055, 0.0060, 0.0074, 0.0070]],\n",
    "        [[0.0079, 0.0059, 0.0131, 0.0063],\n",
    "         [0.0079, 0.0056,  0.0099, 0.0088]]],device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf80b943-9f6e-49b2-83f6-17af1e19ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2],\n",
      "         [3]],\n",
      "\n",
      "        [[3],\n",
      "         [0]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "action_batch  = torch.cat(action)\n",
    "print(action_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3706be86-0066-4549-a4df-cf1e6dfda47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_action_values = state_action_values.gather(2,action_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198fbafd-990e-4608-bc33-02d940ab034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0108],\n",
       "         [0.0070]],\n",
       "\n",
       "        [[0.0063],\n",
       "         [0.0079]]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375df3c9-919c-4e39-930f-b7a2921e5e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[50],\n",
      "         [58]],\n",
      "\n",
      "        [[32],\n",
      "         [40]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d494ba5e-8aea-4315-aa8b-8e92929f9423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50],\n",
      "        [58],\n",
      "        [32],\n",
      "        [40],\n",
      "        [ 4],\n",
      "        [13],\n",
      "        [28],\n",
      "        [35],\n",
      "        [48],\n",
      "        [56]], device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09612f-5fa0-42f6-a78c-3ecba0a29e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40173147-4c45-4fda-b74d-5aee85851098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f3594-f6fc-45d7-a70a-64595c5b725d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "598d11a9-0a3d-4927-969e-e57040b7bb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r . . q . . . .\n",
       ". B . . . . . .\n",
       ". . . . . . k .\n",
       ". . . . . . . .\n",
       ". . . P . . P .\n",
       ". . . . . . . .\n",
       ". . . B . K R .\n",
       ". n . r . . . .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light lastmove b1\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark lastmove a3\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 330)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(150, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(150, 285)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(240, 285)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 195)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(285, 105)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(60, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /></svg>"
      ],
      "text/plain": [
       "Board('r2q4/1B6/6k1/8/3P2P1/8/3B1KR1/1n1r4 w - - 5 65')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.board.push_uci('b2b1q')\n",
    "env.board\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d5ee041-6cc7-4aa7-b85d-c8951b4ee065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Move.from_uci('h8g8'),\n",
       " Move.from_uci('h8f8'),\n",
       " Move.from_uci('e8f8'),\n",
       " Move.from_uci('c8b7'),\n",
       " Move.from_uci('b8c6'),\n",
       " Move.from_uci('a8a7'),\n",
       " Move.from_uci('e7f8'),\n",
       " Move.from_uci('e7d6'),\n",
       " Move.from_uci('e7c5'),\n",
       " Move.from_uci('e7b4'),\n",
       " Move.from_uci('f6g8'),\n",
       " Move.from_uci('f6h5'),\n",
       " Move.from_uci('f6d5'),\n",
       " Move.from_uci('f6g4'),\n",
       " Move.from_uci('f6e4'),\n",
       " Move.from_uci('e8g8'),\n",
       " Move.from_uci('a6b5'),\n",
       " Move.from_uci('h7h6'),\n",
       " Move.from_uci('d7d6'),\n",
       " Move.from_uci('c7c6'),\n",
       " Move.from_uci('g6g5'),\n",
       " Move.from_uci('a6a5'),\n",
       " Move.from_uci('e5e4'),\n",
       " Move.from_uci('h7h5'),\n",
       " Move.from_uci('d7d5'),\n",
       " Move.from_uci('c7c5')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(env.board.legal_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ea27a-3596-4195-a4b9-3febee402ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5484f-dc5d-4843-a798-c371030c8960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf30fff9-d9fe-42b0-9347-44c3448b1995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "125791ed-72ff-40b3-ab71-75d994208136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1e61917-b024-45d0-8ab2-be383c1b52ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "287cecc0-2a1e-4097-b8cb-deec6f3f873c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4224642-4ab2-4473-8fbb-ee49b62761be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a7138a3-bfba-4881-b858-d92cee0c823a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c84ffd-c4c2-418e-ab7a-dd9a892d2fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6c2e1-1f32-487f-af1d-c96cba607ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
